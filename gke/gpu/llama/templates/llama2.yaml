{{- $root := . -}}
apiVersion: jobset.x-k8s.io/v1alpha2
kind: JobSet
metadata:
  name: maxtext-llama2
  labels:
    xpk.google.com/workload: maxtext-llama2
spec:
  failurePolicy:
    maxRestarts: 0
  replicatedJobs:
    - name: slice-job
      replicas: 1
      template:
        spec:
          parallelism: {{ $root.Values.workload.nodes }}
          completions: {{ $root.Values.workload.nodes }}
          backoffLimit: 0   # When any pod fails, the job is failed
          template:
            metadata:
              labels:
                xpk.google.com/workload: maxtext-llama2
            spec:
              schedulingGates:
              - name: "gke.io/topology-aware-auto-scheduling"
              restartPolicy: Never
              hostNetwork: true
              dnsPolicy: ClusterFirstWithHostNet
              terminationGracePeriodSeconds: 30
              tolerations:
              - operator: "Exists"
                key: nvidia.com/gpu
              volumes:
              - name: nvidia-install-dir-host
                hostPath:
                  path: /home/kubernetes/bin/nvidia/lib64
              - name: shared-memory
                emptyDir:
                  medium: "Memory"
                  sizeLimit: 1Gi
              - name: workload-terminated-volume
                emptyDir:
              containers:
              - name: fastrak-daemon
                image: us-docker.pkg.dev/gce-ai-infra/gpudirect-tcpxo/tcpgpudmarxd-dev:v1.0.6-sctp
                imagePullPolicy: Always
                command: 
                - "bash"
                - "-c"
                - |
                  set -ex; chmod 755 /fts/entrypoint_rxdm_container.sh; /fts/entrypoint_rxdm_container.sh --num_hops=2 --num_nics=8 --uid= --alsologtostderr &
                  while [ ! -e "/usr/share/maxtext/workload_terminated" ]; do sleep 10; echo "sleeping"; done
                securityContext:
                  privileged: true
                volumeMounts:
                - name: nvidia-install-dir-host
                  mountPath: /usr/local/nvidia/lib64
                - name: workload-terminated-volume
                  mountPath: /usr/share/maxtext
                env:
                - name: LD_LIBRARY_PATH
                  value: /usr/local/nvidia/lib64
              - name: maxtext-fastrak
                image: "{{ $root.Values.workload.image }}"
                imagePullPolicy: Always
                securityContext:
                  privileged: true
                ports:
                    - containerPort: 6002
                env:
                  - name: NCCL_FASTRAK_ENABLE_CONTROL_CHANNEL
                    value: "0"
                  - name: NCCL_BUFFSIZE
                    value: "8388608"
                  - name: REPLICATED_JOB_NAME
                    valueFrom:
                      fieldRef:
                        fieldPath: metadata.annotations['jobset.sigs.k8s.io/replicatedjob-name']
                  - name: JOBSET_NAME
                    valueFrom:
                      fieldRef:
                        fieldPath: metadata.annotations['jobset.sigs.k8s.io/jobset-name']
                  - name: JAX_COORDINATOR_ADDRESS
                    value: "$(JOBSET_NAME)-$(REPLICATED_JOB_NAME)-0-0.$(JOBSET_NAME)"
                  - name: NNODES
                    value: "{{ $root.Values.workload.nodes }}"
                  - name: NODE_RANK
                    valueFrom:
                      fieldRef:
                        fieldPath: metadata.annotations['batch.kubernetes.io/job-completion-index']
                  - name: USE_GPUDIRECT
                    value: "fastrak"
                  - name: GPUS_PER_NODE
                    value: "8"
                  - name: JAX_COORDINATOR_PORT
                    value: "6002"
                  - name: LD_LIBRARY_PATH
                    value: /usr/local/nvidia/lib64

                  - name: COMMAND
                    value: {{ $root.Values.workload.train_command }}
                  - name: XLA_FLAGS
                    value: {{ $root.Values.workload.xla_flags }}
                  - name: NCCL_FASTRAK_CTRL_DEV
                    value: "eth0"
                  - name: NCCL_FASTRAK_IFNAME
                    value: "eth1,eth2,eth3,eth4,eth5,eth6,eth7,eth8"
                  - name: NCCL_SOCKET_IFNAME
                    value: "eth0"
                  - name: NCCL_CROSS_NIC
                    value: "0"
                  - name: NCCL_ALGO
                    value: "Ring"
                  - name: NCCL_PROTO
                    value: "Simple"
                  - name: NCCL_MIN_NCHANNELS
                    value: "4"
                  - name: NCCL_DYNAMIC_CHUNK_SIZE
                    value: "524288"
                  - name: NCCL_P2P_NET_CHUNKSIZE
                    value: "524288"
                  - name: NCCL_P2P_PCI_CHUNKSIZE
                    value: "524288"
                  - name: NCCL_P2P_NVL_CHUNKSIZE
                    value: "1048576"
                  - name: NCCL_FASTRAK_NUM_FLOWS
                    value: "2"
                  - name: NCCL_FASTRAK_USE_SNAP
                    value: "1"
                  - name: NCCL_FASTRAK_ENABLE_CONTROL_CHANNEL
                    value: "0"
                  - name: NCCL_BUFFSIZE
                    value: "8388608"
                  - name: CUDA_VISIBLE_DEVICES
                    value: "0,1,2,3,4,5,6,7"
                  - name: NCCL_NET_GDR_LEVEL
                    value: "PIX"
                  - name: NCCL_FASTRAK_ENABLE_HOTPATH_LOGGING
                    value: "0"
                  - name: NCCL_FASTRAK_USE_LLCM
                    value: "1"
                  - name: NCCL_DEBUG
                    value: "VERSION"
                  - name: TF_CPP_VMODULE
                    value: "profile_guided_latency_estimator=10"
                  - name: TF_CPP_MIN_LOG_LEVEL
                    value: "0"
                  - name: TF_CPP_MAX_LOG_LEVEL
                    value: "100"
                  - name: XLA_PYTHON_CLIENT_MEM_FRACTION
                    value: "0.85"
                  - name: CUDA_DEVICE_MAX_CONNECTIONS
                    value: "1"
                  - name: NVTE_FUSED_ATTN
                    value: "1"

                command:
                  - "bash"
                  - "-c"
                  - |
                    echo XPK Start: $(date) ; _sigterm() ( kill -SIGTERM $! 2>/dev/null;); trap _sigterm SIGTERM;(cd /deps && bash gpu_multi_process_run.sh) & PID=$!; while kill -0 $PID 2>/dev/null; do sleep 5; done; wait $PID; EXIT_CODE=$? ;  echo XPK End: $(date); echo EXIT_CODE=$EXIT_CODE; echo Main app is done > /usr/share/maxtext/workload_terminated;
                volumeMounts:
                  - name: nvidia-install-dir-host
                    mountPath: /usr/local/nvidia/lib64
                  - name: shared-memory
                    mountPath: /dev/shm
                  - name: workload-terminated-volume
                    mountPath: /usr/share/maxtext
                resources:
                  limits:
                    nvidia.com/gpu: 8
