workload:
  nodes: 8
  image: "gcr.io/supercomputer-testing/yangyuwei/maxtext-fastrak:06-28-2024-nightly"
  xla_flags: "--xla_gpu_enable_latency_hiding_scheduler=true --xla_gpu_enable_triton_gemm=false --xla_gpu_graph_level=0 --xla_gpu_enable_highest_priority_async_stream=true --xla_gpu_all_reduce_combine_threshold_bytes=1073741824 --xla_gpu_all_gather_combine_threshold_bytes=1073741824 --xla_gpu_reduce_scatter_combine_threshold_bytes=67108864 --xla_gpu_enable_pipelined_all_gather=true --xla_gpu_enable_pipelined_reduce_scatter=true --xla_gpu_enable_pipelined_all_reduce=true --xla_gpu_enable_while_loop_double_buffering=true --xla_gpu_enable_triton_softmax_fusion=false --xla_gpu_enable_all_gather_combine_by_dim=false --xla_gpu_enable_reduce_scatter_combine_by_dim=false --xla_disable_hlo_passes=rematerialization"
  train_command: "python MaxText/train.py MaxText/configs/base.yml hardware=gpu run_name=maxtext-llama2-7b steps=30 dcn_data_parallelism=8 ici_fsdp_parallelism=8 num_slices=8 per_device_batch_size=2 max_target_length=4096 model_name=llama2-7b enable_checkpointing=false attention=cudnn_flash_te remat_policy=minimal use_iota_embed=true scan_layers=false dataset_type=synthetic async_checkpointing=false base_output_directory=gs://runner-maxtext-logs profiler=nsys logits_dot_in_fp32=false"
