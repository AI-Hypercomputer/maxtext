# from transformers import AutoModel

# model = AutoModel.from_pretrained("deepseek-ai/DeepSeek-V2-Lite", use_auth_token=True)


"""Check if the logits generated by a model's MaxText implementation matches hf logits for the same inputs"""
import argparse
import sys
import os
from absl import app
import jsonlines
import json
import pickle

current_dir = os.path.dirname(os.path.abspath(__file__))
maxtext_parent_dir = os.path.dirname(current_dir)
sys.path.append(maxtext_parent_dir)

import max_logging

max_logging.log(f"Added parent directory = {maxtext_parent_dir}")

import common_types
import jax
import jax.numpy as jnp
import numpy as np
import pyconfig
import train
from tabulate import tabulate
from google.cloud import storage


prompt_text = "We can think of self-attention as a mechanism that enhances the information content of an input embedding by including information about the inputâ€™s context. In other words, the self-attention mechanism enables the model to weigh the importance of different elements in an input sequence and dynamically adjust their influence on the output."


def upload_blob(bucket_name, source_file_name, destination_blob_name):
  """Uploads a file to the bucket."""
  storage_client = storage.Client()
  bucket = storage_client.get_bucket(bucket_name)
  blob = bucket.blob(destination_blob_name)
  blob.upload_from_filename(source_file_name)


def get_data_hf(config, prompt_text, hf_token, model_id="deepseek-ai/DeepSeek-V3"):
  from huggingface_hub import login
  from transformers import AutoTokenizer, AutoModelForCausalLM
  import jax.numpy as jnp
  import numpy as np
  import torch

  """Get data (tokens, logits) from a Hugging Face model for the test at hf_data_index"""
  login(token=hf_token)

  tokenizer = AutoTokenizer.from_pretrained(model_id)
  # hf_model = AutoModelForCausalLM.from_pretrained(
  #     model_id, trust_remote_code=True, torch_dtype=getattr(torch, config.dtype.name)
  # )

  input_ids = tokenizer.encode(prompt_text, return_tensors="pt")[:, : config.max_target_length]

  # Get the logits for the prompt + completion using Hugging Face model
  # with torch.no_grad():
  #   outputs = hf_model(input_ids)
  #   logits = outputs.logits.cpu().numpy().astype("float32")

  # Prepare tokens and logits
  tokens = input_ids.tolist()[0]

  max_logging.log(f"config.global_batch_size_to_train_on={config.global_batch_size_to_train_on}")

  ids = np.asarray(tokens, dtype=np.int32)

  # Use Hugging Face logits
  # logits = np.asarray(logits[0], dtype=np.float32)

  max_logging.log(f'prompt="{prompt_text}" raw ids={ids}')

  # Create decoder segment ids and positions
  decoder_segment_ids = jax.numpy.zeros(s) + common_types.DECODING_ACTIVE_SEQUENCE_INDICATOR
  decoder_segment_ids = (
      jax.numpy.ones((config.global_batch_size_to_train_on, config.max_target_length))
      * common_types.DECODING_ACTIVE_SEQUENCE_INDICATOR
  )
  decoder_positions = jnp.stack(
      [jnp.arange(config.max_target_length, dtype=jnp.int32) for _ in range(config.global_batch_size_to_train_on)]
  )

  ids = jnp.stack([ids for _ in range(config.global_batch_size_to_train_on)])
  max_logging.log(f"ids={ids}, decoder_segment_ids = {decoder_segment_ids}, decoder_positions= {decoder_positions}")

  return ids, decoder_segment_ids, decoder_positions


def main(argv):
  jax.config.update("jax_default_prng_impl", "unsafe_rbg")
  os.environ["TF_CPP_MIN_LOG_LEVEL"] = "0"

  config = pyconfig.initialize(argv)
  # run forward pass on hf llama2 model add hf token
  ids, decoder_segment_ids, decoder_positions = get_data_hf(config, prompt_text, hf_token="")

  # initialize the model with weights from reference ckpt
  (
      init_rng,
      _,
      _,
      _,
      model,
      _,
      _,
      _,
      _,
      state,
  ) = train.setup_train_loop(config)

  full_train_logits = model.apply(
      state.params,
      ids,
      decoder_positions,
      decoder_segment_ids,
      enable_dropout=False,
      rngs={"aqt": init_rng},
  )
  jax.debug.print("full_train_logits before: {full_train_logits}", full_train_logits=full_train_logits)
  jax.debug.print("full_train_logits.sharding before: {x}", x=full_train_logits.sharding)
  jax.debug.print("full_train_logits.shape before: {x}", x=full_train_logits.shape)
  full_train_logits = jax.experimental.multihost_utils.process_allgather(full_train_logits)
  
  # print(f"full_train_logits: {full_train_logits.shape}")
  jax.debug.print("full_train_logits after: {full_train_logits}", full_train_logits=full_train_logits)
  print(f"full_train_logits.shape after: {full_train_logits.shape}")

  from google.cloud import storage
  gcs_bucket = "ranran-multipod-dev"
  output_path = "maxtext-logits-long-prompt-shard"
  model_id = "deepseek-ai/DeepSeek-V3"

  with open(output_path, "wb") as f:
      pickle.dump(full_train_logits, f)

  with jsonlines.open(output_path, "w") as f:
    for row in full_train_logits:
        json_record = json.dumps(row.tolist())
        f.write(json_record + '\n')
    print(f"File is stored locally at {output_path}.")

  upload_blob(gcs_bucket, output_path, f"maxtext-logits/{model_id}/{output_path}")
  print(f"File is uploaded to gs://{gcs_bucket}/maxtext-logits/{model_id}/{output_path}.")

  # token_size = logits_hf.shape[0]
  # max_logging.log(f"{token_size=}")
  # logits_maxtext = full_train_logits[0, 0, :token_size, :]
  # logits_hf = logits_hf[:token_size, :]
  # max_logging.log(f"Max Numerical Difference {np.abs(logits_hf - logits_maxtext).max()}")

  # max_logging.log(f"{logits_maxtext=}")
  # max_logging.log(f"{logits_hf=}")

  # maxtext_probabilities = jax.nn.softmax(logits_maxtext, axis=-1)
  # hf_probabilities = jax.nn.softmax(logits_hf, axis=-1)

  # max_logging.log(f"{maxtext_probabilities}=")
  # max_logging.log(f"{hf_probabilities}=")

  # kl_div = jax.numpy.sum(jax.scipy.special.kl_div(hf_probabilities, maxtext_probabilities), axis=-1)
  # max_logging.log(f"KL divergence = {kl_div}, max KL divergence = {jax.numpy.max(kl_div)}")

  # metrics = {}
  # metrics["max_kl_div"] = jax.numpy.max(kl_div)
  # metrics["l1_diff_mean"] = np.abs(logits_hf - logits_maxtext).mean()
  # metrics["abs_diff"] = np.abs(logits_hf - logits_maxtext).max()

  # ranking_maxtext = np.argsort(logits_maxtext, axis=1)[:, -5:]
  # ranking_hf = np.argsort(logits_hf, axis=1)[:, -5:]

  # # for each token, 1 if there is a disagreement in the top 5 of next tokens, 0 otherwise
  # metrics["disagreement_top5"] = np.mean((np.abs(ranking_hf - ranking_maxtext) > 0).sum(axis=1) > 0)

  # table = [[key, value] for key, value in metrics.items()]
  # print(tabulate(table, headers=["Metric", "Value"], tablefmt="orgtbl"))


if __name__ == "__main__":
  # jax.config.update("jax_default_prng_impl", "unsafe_rbg")
  # os.environ["TF_CPP_MIN_LOG_LEVEL"] = "0"

  # parser = argparse.ArgumentParser()
  # test_args, _ = parser.parse_known_args()
  # config = pyconfig.initialize(argv)

  # pyconfig.initialize(sys.argv)
  # cfg = pyconfig._config
  app.run(main)