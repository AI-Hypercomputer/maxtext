{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GSPO Llama3.1-8B Demo\n",
        "\n",
        "This notebook demonstrates GSPO (Group Sequence Policy Optimization) training using the unified `rl_train` entry point. GSPO shares the same infrastructure as GRPO but applies a sequence-aware clipping objective. Use this notebook when you want to experiment with the `loss_algo=gspo-token` mode for reasoning workloads.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Access to a TPU VM with sufficient memory for Llama3.1-8B or a multi-host Pathways cluster\n",
        "- A scanned checkpoint compatible with MaxText\n",
        "- A valid Hugging Face access token if the tokenizer/model pull requires authentication\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Install dependencies and set up the environment:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone MaxText repository\n",
        "!git clone https://github.com/AI-Hypercomputer/maxtext.git\n",
        "%cd maxtext\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!chmod +x setup.sh\n",
        "!./setup.sh\n",
        "\n",
        "# Install GRPO/GSPO-specific dependencies\n",
        "!./src/MaxText/examples/install_tunix_vllm_requirement.sh\n",
        "\n",
        "# Install additional requirements\n",
        "%pip install --force-reinstall numpy==2.1.2\n",
        "%pip install nest_asyncio\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()  # Fix for Colab event loop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Set up the training parameters. Defaults target Llama3.1-8B with GSPO loss:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multi-host Pathways\n",
        "\n",
        "To use Pathways with GSPO:\n",
        "- Confirm `use_pathways=True` inside `rl.yml` (enabled by default).\n",
        "- Override `trainer_devices_fraction` and `sampler_devices_fraction` in `config_argv` to partition the mesh across hosts.\n",
        "- Export Pathways runtime variables such as `JAX_PLATFORMS=proxy`, `ENABLE_PATHWAYS_PERSISTENCE=1`, and `JAX_BACKEND_TARGET=grpc://<controller-ip>:29000` before invoking the training cell.\n",
        "- Adjust `chips_per_vm` to match your TPU slice topology so trainer and rollout workers shard correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration for GSPO training\n",
        "import os\n",
        "\n",
        "# Set up paths (adjust if needed)\n",
        "MAXTEXT_REPO_ROOT = os.path.expanduser(\"~\") + \"/maxtext\"\n",
        "\n",
        "# Hardcoded defaults for Llama3.1-8B GSPO\n",
        "MODEL_NAME = \"llama3.1-8b\"\n",
        "HF_REPO_ID = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "CHAT_TEMPLATE_PATH = \"src/MaxText/examples/chat_templates/gsm8k_rl.json\"\n",
        "LOSS_ALGO = \"gspo-token\"\n",
        "\n",
        "# Required: Set these before running\n",
        "MODEL_CHECKPOINT_PATH = \"gs://maxtext-model-checkpoints/llama3.1-8b/2025-01-23-19-04/scanned/0/items\"  # Update!\n",
        "OUTPUT_DIRECTORY = \"/tmp/gspo_output\"  # Update!\n",
        "HF_TOKEN = os.environ.get(\"HF_TOKEN\", \"\")  # Set HF_TOKEN environment variable\n",
        "\n",
        "# Optional: Override training parameters\n",
        "STEPS = 10  # Reduced for demo purposes\n",
        "PER_DEVICE_BATCH_SIZE = 1\n",
        "LEARNING_RATE = 3e-6\n",
        "NUM_GENERATIONS = 2\n",
        "GSPO_BETA = 0.08\n",
        "GSPO_EPSILON = 0.2\n",
        "CHIPS_PER_VM = 4\n",
        "\n",
        "print(f\"üìÅ MaxText Home: {MAXTEXT_REPO_ROOT}\")\n",
        "print(f\"ü§ñ Model: {MODEL_NAME}\")\n",
        "print(f\"üì¶ Checkpoint: {MODEL_CHECKPOINT_PATH}\")\n",
        "print(f\"üíæ Output: {OUTPUT_DIRECTORY}\")\n",
        "print(f\"üîë HF Token: {'‚úÖ Set' if HF_TOKEN else '‚ùå Missing - set HF_TOKEN env var'}\")\n",
        "print(f\"üìä Steps: {STEPS}\")\n",
        "print(f\"üéØ Loss Algorithm: {LOSS_ALGO}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required modules\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add MaxText to Python path\n",
        "maxtext_path = Path(MAXTEXT_REPO_ROOT) / \"src\" / \"MaxText\"\n",
        "sys.path.insert(0, str(maxtext_path))\n",
        "\n",
        "from MaxText import pyconfig, max_utils\n",
        "from MaxText.rl.train_rl import rl_train\n",
        "import jax\n",
        "\n",
        "# Initialize JAX and Pathways\n",
        "import pathwaysutils\n",
        "pathwaysutils.initialize()\n",
        "jax.config.update(\"jax_default_prng_impl\", \"unsafe_rbg\")\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"0\"\n",
        "os.environ[\"SKIP_JAX_PRECOMPILE\"] = \"1\"  # Faster startup for vLLM\n",
        "\n",
        "if \"xla_tpu_spmd_rng_bit_generator_unsafe\" not in os.environ.get(\"LIBTPU_INIT_ARGS\", \"\"):\n",
        "    os.environ[\"LIBTPU_INIT_ARGS\"] = (\n",
        "        os.environ.get(\"LIBTPU_INIT_ARGS\", \"\") + \" --xla_tpu_spmd_rng_bit_generator_unsafe=true\"\n",
        "    )\n",
        "\n",
        "print(\"‚úÖ Successfully imported modules\")\n",
        "print(f\"üìÅ MaxText path: {maxtext_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build configuration for GSPO training\n",
        "config_file = os.path.join(MAXTEXT_REPO_ROOT, \"src/MaxText/configs/rl.yml\")\n",
        "\n",
        "# Verify chat template exists\n",
        "if not os.path.exists(os.path.join(MAXTEXT_REPO_ROOT, CHAT_TEMPLATE_PATH)):\n",
        "    raise FileNotFoundError(f\"Chat template not found: {CHAT_TEMPLATE_PATH}\")\n",
        "\n",
        "config_argv = [\n",
        "    \"\",  # argv[0] placeholder\n",
        "    config_file,\n",
        "    f\"model_name={MODEL_NAME}\",\n",
        "    f\"tokenizer_path={HF_REPO_ID}\",\n",
        "    f\"hf_model_name={HF_REPO_ID}\",\n",
        "    f\"chat_template_path={CHAT_TEMPLATE_PATH}\",\n",
        "    f\"load_parameters_path={MODEL_CHECKPOINT_PATH}\",\n",
        "    f\"base_output_directory={OUTPUT_DIRECTORY}\",\n",
        "    f\"hf_access_token={HF_TOKEN}\",\n",
        "    f\"steps={STEPS}\",\n",
        "    f\"per_device_batch_size={PER_DEVICE_BATCH_SIZE}\",\n",
        "    f\"learning_rate={LEARNING_RATE}\",\n",
        "    f\"num_generations={NUM_GENERATIONS}\",\n",
        "    f\"grpo_beta={GSPO_BETA}\",\n",
        "    f\"grpo_epsilon={GSPO_EPSILON}\",\n",
        "    f\"chips_per_vm={CHIPS_PER_VM}\",\n",
        "    f\"loss_algo={LOSS_ALGO}\",\n",
        "]\n",
        "\n",
        "print(f\"üîß Initializing configuration from: {config_file}\")\n",
        "config = pyconfig.initialize(config_argv)\n",
        "max_utils.print_system_information()\n",
        "\n",
        "print(\"\\n‚úÖ Configuration initialized successfully\")\n",
        "print(f\"üìä Training steps: {config.steps}\")\n",
        "print(f\"üìÅ Output directory: {config.base_output_directory}\")\n",
        "print(f\"ü§ñ Model: {config.model_name}\")\n",
        "print(f\"üéØ Loss algorithm: {config.loss_algo}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute GSPO training\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üöÄ Starting GSPO Training...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "try:\n",
        "    rl_train(config)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"‚úÖ GSPO Training Completed Successfully!\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"üìÅ Checkpoints saved to: {config.checkpoint_dir}\")\n",
        "    print(f\"üìä TensorBoard logs: {config.tensorboard_dir}\")\n",
        "    print(f\"üéØ Model ready for inference!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"‚ùå GSPO Training Failed!\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Error: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    print(\"\\nüí° Common issues:\")\n",
        "    print(\"  - Check that MODEL_CHECKPOINT_PATH points to a valid checkpoint\")\n",
        "    print(\"  - Ensure HF_TOKEN environment variable is set\")\n",
        "    print(\"  - Verify OUTPUT_DIRECTORY is writable\")\n",
        "    print(\"  - Check hardware requirements (TPU/GPU availability)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Learn More\n",
        "\n",
        "- **CLI Usage**: `python3 -m src.MaxText.rl.train_rl src/MaxText/configs/rl.yml --model_name=llama3.1-8b loss_algo=gspo-token ...`\n",
        "- **Configuration Reference**: `src/MaxText/configs/rl.yml`\n",
        "- **Implementation**: `src/MaxText/rl/train_rl.py` (search for `loss_algo` handling)\n",
        "- **Related Notebook**: `src/MaxText/examples/grpo_llama3_1_8b_demo.ipynb` for GRPO comparison\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
