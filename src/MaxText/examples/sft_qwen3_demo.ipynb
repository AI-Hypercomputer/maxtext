{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AI-Hypercomputer/maxtext/blob/main/src/MaxText/examples/sft_qwen3_demo.ipynb)\n",
    "\n",
    "# Qwen3-0.6B Supervised Fine-Tuning (SFT) Demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook can run on the **public TPU v5e-1**\n",
    "\n",
    "This notebook demonstrates how to perform Supervised Fine-Tuning (SFT) on Qwen3-0.6B using the Hugging Face ultrachat_200k dataset with Tunix integration for efficient training.\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "**Dataset Link:** https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k\n",
    "\n",
    "### Dataset Information:\n",
    "- **Name:** HuggingFaceH4/ultrachat_200k\n",
    "- **Type:** Supervised Fine-Tuning dataset\n",
    "- **Size:** ~200k conversations\n",
    "- **Format:** Chat conversations with human-AI pairs\n",
    "- **Splits:** train_sft, test_sft\n",
    "- **Data columns:** ['messages']\n",
    "\n",
    "### Dataset Structure:\n",
    "Each example contains a 'messages' field with:\n",
    "- **role:** 'user' or 'assistant'\n",
    "- **content:** The actual message text\n",
    "\n",
    "### Example data format:\n",
    "```json\n",
    "{\n",
    "  \"messages\": [\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The capital of France is Paris.\"}\n",
    "  ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "### Change Runtime Type\n",
    "\n",
    "**Instructions:**\n",
    "1.  Navigate to the menu at the top of the screen.\n",
    "2.  Click on **Runtime**.\n",
    "3.  Select **Change runtime type** from the dropdown menu.\n",
    "4.  Select **v5e-1 TPU** as the **Hardware accelerator**.\n",
    "5. Click on **Save**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Your Hugging Face Token\n",
    "\n",
    "To access model checkpoint from the Hugging Face Hub, you need to authenticate with a personal access token.\n",
    "\n",
    "**Follow these steps to get your token:**\n",
    "\n",
    "1.  **Navigate to the Access Tokens page** in your Hugging Face account settings. You can go there directly by visiting this URL:\n",
    "    *   [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)\n",
    "\n",
    "2.  **Create a new token** by clicking the **\"+ Create new token\"** button.\n",
    "\n",
    "3.  **Give your token a name** and assign it a **`read` role**. The `read` role is sufficient for downloading models.\n",
    "\n",
    "4.  **Copy the generated token**. You will need to paste it in the next step.\n",
    "\n",
    "**Follow these steps to store your token:**\n",
    "\n",
    "1. On the left sidebar of your Colab window, click the key icon (the Secrets tab).\n",
    "\n",
    "2. Click **\"+ Add new secret\"**.\n",
    "\n",
    "3. Set the Name as **HF_TOKEN**.\n",
    "\n",
    "4. Paste your token into the Value field.\n",
    "\n",
    "5. Ensure the Notebook access toggle is turned On."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KPyOE8e9WbO"
   },
   "outputs": [],
   "source": [
    "# Install maxtext and dependencies\n",
    "# 1. Install uv, a fast Python package installer\n",
    "!pip install uv\n",
    "\n",
    "# 2. Install MaxText and its dependencies\n",
    "!uv pip install maxtext --resolution=lowest\n",
    "!install_maxtext_github_deps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart Session\n",
    "To apply certain changes, you need to restart the session.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Navigate to the menu at the top of the screen.\n",
    "2.  Click on **Runtime**.\n",
    "3.  Select **Restart session** from the dropdown menu.\n",
    "\n",
    "You will be asked to confirm the action in a pop-up dialog. Click on **Yes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the maxtext environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MaxText\n",
    "try:\n",
    "  import MaxText\n",
    "  from MaxText import pyconfig\n",
    "  from MaxText.sft.sft_trainer import train as sft_train\n",
    "  import os\n",
    "\n",
    "  MAXTEXT_AVAILABLE = True\n",
    "  print(\"✓ MaxText imports successful\")\n",
    "except ImportError as e:\n",
    "  print(f\"⚠️ MaxText not available: {e}\")\n",
    "  MAXTEXT_AVAILABLE = False\n",
    "\n",
    "# Hugging Face Authentication Setup\n",
    "from huggingface_hub import login\n",
    "\n",
    "# use google colab userdata to get the HF token\n",
    "from google.colab import userdata\n",
    "\n",
    "\n",
    "MAXTEXT_REPO_ROOT = os.path.dirname(MaxText.__file__)\n",
    "print(f\"MaxText installation path: {MAXTEXT_REPO_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the model, checkpoint path and output directory\n",
    "MODEL_NAME = \"qwen3-0.6b\"\n",
    "# If you do not have the checkpoint this colab will download the checkpoint from HF and store at `\"{MAXTEXT_REPO_ROOT}/qwen_checkpoint\\\"`\n",
    "MODEL_CHECKPOINT_PATH = f\"{MAXTEXT_REPO_ROOT}/qwen_checkpoint\"\n",
    "\n",
    "# This is the directory where the fine-tuned model will be saved\n",
    "# You can change it to any path you want\n",
    "BASE_OUTPUT_DIRECTORY = \"/tmp/out/maxtext_qwen06\"\n",
    "\n",
    "# Set your Hugging Face token as a secret in the Google Colab\n",
    "HF_TOKEN = userdata.get(\"HF_TOKEN\")\n",
    "# HF_TOKEN = \"your_actual_token_here\" - use this for a private jupyter lab\n",
    "login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the command to convert the HF model to the MaxText format\n",
    "if not os.path.exists(MODEL_CHECKPOINT_PATH):\n",
    "  !python3 -m MaxText.utils.ckpt_conversion.to_maxtext \\\n",
    "        $MAXTEXT_REPO_ROOT/configs/base.yml \\\n",
    "        model_name=$MODEL_NAME \\\n",
    "        base_output_directory=$MODEL_CHECKPOINT_PATH \\\n",
    "        hf_access_token=$HF_TOKEN \\\n",
    "        use_multimodal=false \\\n",
    "        scan_layers=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize jax and set model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CxzKMBQd_U5-"
   },
   "outputs": [],
   "source": [
    "# this is the code to initialize jax if it's not initialized in the cell above\n",
    "import jax\n",
    "\n",
    "if not jax.distributed.is_initialized():\n",
    "  jax.distributed.initialize()\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "In-jdp1AAwrL"
   },
   "outputs": [],
   "source": [
    "# Fixed configuration setup for Qwen-0.6B on small TPU\n",
    "if MAXTEXT_AVAILABLE:\n",
    "  config_argv = [\n",
    "    \"\",\n",
    "    f\"{MAXTEXT_REPO_ROOT}/configs/sft.yml\",  # base SFT config\n",
    "    f\"load_parameters_path={MODEL_CHECKPOINT_PATH}/0/items/\",  # Load pre-trained weights!, replace with your checkpoint path\n",
    "    f\"model_name={MODEL_NAME}\",\n",
    "    \"steps=20\",  # very short run for testing\n",
    "    \"per_device_batch_size=1\",  # minimal to avoid OOM\n",
    "    \"max_target_length=1024\",\n",
    "    \"learning_rate=2.0e-5\",  # safe small LR\n",
    "    \"eval_steps=5\",\n",
    "    \"weight_dtype=bfloat16\",\n",
    "    \"dtype=bfloat16\",\n",
    "    \"hf_path=HuggingFaceH4/ultrachat_200k\",  # HuggingFace dataset/model if needed\n",
    "    f\"hf_access_token={HF_TOKEN}\",\n",
    "    f\"base_output_directory={BASE_OUTPUT_DIRECTORY}\",\n",
    "    \"run_name=sft_qwen0.6b_test\",\n",
    "    \"tokenizer_path=Qwen/Qwen3-0.6B\",  # Qwen tokenizer\n",
    "    \"eval_interval=10\",\n",
    "    \"profiler=xplane\",\n",
    "  ]\n",
    "\n",
    "  # Initialize configuration using MaxText's pyconfig\n",
    "  config = pyconfig.initialize(config_argv)\n",
    "\n",
    "  print(\"✓ Fixed configuration loaded:\")\n",
    "  print(f\"  - Model: {config.model_name}\")\n",
    "  print(f\"  - Dataset: {config.hf_path}\")\n",
    "  print(f\"  - Steps: {config.steps}\")\n",
    "  print(f\"  - Use SFT: {config.use_sft}\")\n",
    "  print(f\"  - Learning Rate: {config.learning_rate}\")\n",
    "else:\n",
    "  print(\"MaxText not available - cannot load configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJE1ookSAzz-"
   },
   "source": [
    "## Train the model, save the tuned model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mgwpNgQYCJEd"
   },
   "outputs": [],
   "source": [
    "#  Execute the training using MaxText SFT trainer's train() function\n",
    "if MAXTEXT_AVAILABLE:\n",
    "  print(\"=\" * 60)\n",
    "  print(\"EXECUTING ACTUAL TRAINING\")\n",
    "  print(\"=\" * 60)\n",
    "\n",
    "  sft_train(config)\n",
    "\n",
    "print(\"Training complete!\")\n",
    "print(\"Model saved at: \", BASE_OUTPUT_DIRECTORY)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V5E1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
