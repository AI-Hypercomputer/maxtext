{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRPO Llama3.1-8B Demo: Direct Function Call\n",
    "\n",
    "This notebook demonstrates GRPO training by directly calling the `rl_train` function from `rl_trainer.py`.\n",
    "\n",
    "## What is GRPO?\n",
    "\n",
    "GRPO (Group Relative Policy Optimization) is an RL algorithm that enhances reasoning abilities of LLMs by:\n",
    "1. Generating multiple responses for each prompt\n",
    "2. Evaluating responses using reward models  \n",
    "3. Calculating relative advantages to update the policy\n",
    "\n",
    "\n",
    "This notebook imports and calls the `rl_train` function \n",
    "\n",
    "## Hardware Requirements\n",
    "\n",
    "- Single host TPUVM (v6e-8/v5p-8) or multi-host with Pathways\n",
    "- Sufficient memory for Llama3.1-8B model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install dependencies and set up the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone MaxText repository\n",
    "!git clone https://github.com/AI-Hypercomputer/maxtext.git\n",
    "%cd maxtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install GRPO-specific dependencies\n",
    "!./src/MaxText/examples/install_tunix_vllm_requirement.sh\n",
    "\n",
    "# Install additional requirements\n",
    "%uv pip install --force-reinstall numpy==2.1.2\n",
    "%uv pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Fix for Colab event loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up the training parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for GRPO training\n",
    "import os\n",
    "\n",
    "# Set up paths\n",
    "MAXTEXT_REPO_ROOT = os.path.expanduser(\"~\") + \"/maxtext\"\n",
    "print(f\"MaxText Home directory: {MAXTEXT_REPO_ROOT}\")\n",
    "\n",
    "# Training configuration\n",
    "MODEL_CHECKPOINT_PATH = \"gs://zhehui_tpu/llama3.1-8b-Instruct/llama3.1-8b-Instruct/scanned-pathways/0/items\"\n",
    "OUTPUT_DIRECTORY = \"/tmp/grpo_output\"\n",
    "STEPS = 10  # Reduced for demo purposes\n",
    "# Please make sure your token has the right permissions!!!!!!\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\", \"YOUR_HF_TOKEN\")\n",
    "\n",
    "print(f\"Model checkpoint: {MODEL_CHECKPOINT_PATH}\")\n",
    "print(f\"Output directory: {OUTPUT_DIRECTORY}\")\n",
    "print(f\"Training steps: {STEPS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GRPO training function directly\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add MaxText to Python path\n",
    "maxtext_path = Path(MAXTEXT_REPO_ROOT) / \"src\" / \"MaxText\"\n",
    "sys.path.insert(0, str(maxtext_path))\n",
    "\n",
    "# Import required modules\n",
    "from MaxText import pyconfig\n",
    "from MaxText.rl.train_rl import rl_train, setup_configs_and_devices\n",
    "\n",
    "print(\"‚úÖ Successfully imported GRPO training function\")\n",
    "print(f\"üìÅ MaxText path: {maxtext_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build configuration for GRPO training\n",
    "config_argv = [\n",
    "    \"\",  # Placeholder for argv[0]\n",
    "    os.path.join(MAXTEXT_REPO_ROOT, \"src/MaxText/configs/rl.yml\"),  # Base config\n",
    "    f\"model_name=llama3.1-8b\",\n",
    "    f\"tokenizer_path=meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    f\"load_parameters_path={MODEL_CHECKPOINT_PATH}\",\n",
    "    f\"hf_access_token={HF_TOKEN}\",\n",
    "    \"run_name=test\"\n",
    "]\n",
    "\n",
    "# Create configuration object\n",
    "trainer_config, sampler_config, trainer_devices, sampler_devices = setup_configs_and_devices(config_argv)\n",
    "\n",
    "print(\"‚úÖ Configuration created successfully\")\n",
    "print(f\"üìä Training steps: {trainer_config.steps}\")\n",
    "print(f\"üìÅ Output directory: {trainer_config.base_output_directory}\")\n",
    "print(f\"ü§ñ Model: {trainer_config.model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute GRPO training directly\n",
    "try:\n",
    "    # Call the rl_train function\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Starting GRPO Training...\")\n",
    "    print(\"=\"*80)\n",
    "    grpo_trainer, rl_cluster = rl_train(trainer_config, sampler_config, trainer_devices, sampler_devices)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ GRPO Training Completed Successfully!\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"üìÅ Checkpoints and logs saved to: {trainer_config.base_output_directory}\")\n",
    "    print(f\"üéØ Final model ready for inference!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚ùå GRPO Training Failed!\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    print(\"\\nPlease check the error message and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìö **Learn More**\n",
    "- See `src/MaxText/examples/grpo_runner.py` for CLI usage\n",
    "- Check `src/MaxText/configs/grpo.yml` for configuration options\n",
    "- Read `src/MaxText/examples/README.md` for more examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zhehuichen_google_com",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
