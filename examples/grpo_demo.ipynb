{
  "cells": [
    {
      "metadata": {},
      "id": "abdhOBYHqYz6",
      "cell_type": "markdown",
      "source": [
        "\u003ca href=\"https://colab.research.google.com/github/google/tunix/blob/main/examples/grpo_demo.ipynb\" \u003e\u003cimg src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/\u003e\u003c/a\u003e\n",
        "\n",
        "This tutorial demonstrates training the Gemma 2B model on the GSM8K math\n",
        "reasoning benchmark using Group Relative Policy Optimization (GRPO). Learn how\n",
        "GRPO can enhance your model's problem-solving skills on mathematical word\n",
        "problems.\n",
        "\n",
        "GRPO is an RL algorithm designed to enhance the reasoning abilities of LLMs. It\n",
        "is a variant of Proximal Policy Optimization (PPO) that reduces memory usage by\n",
        "eliminating the need for a separate value function model. GRPO works by\n",
        "generating multiple responses for a given prompt, evaluating these responses\n",
        "using a reward model, and then calculating a relative advantage based on the\n",
        "group's performance to update the policy.\n",
        "\n",
        "In this tutorial we use Colab's `v2-8` TPU. Let's get started!"
      ]
    },
    {
      "metadata": {},
      "id": "afofSj37qYz6",
      "cell_type": "markdown",
      "source": [
        "## Install necessary libraries"
      ]
    },
    {
      "metadata": {},
      "id": "Z03GnyApTn1j",
      "cell_type": "code",
      "source": [
        "!pip install -q kagglehub\n",
        "\n",
        "!pip install -q tensorflow\n",
        "!pip install -q tensorboardX\n",
        "!pip install -q grain\n",
        "!pip install -q git+https://github.com/google/tunix\n",
        "!pip install -q git+https://github.com/google/qwix\n",
        "\n",
        "!pip uninstall -q -y flax\n",
        "!pip install -q git+https://github.com/google/flax.git"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "LnF9ZACiTn1k",
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ]
    },
    {
      "metadata": {},
      "id": "McTNo_r8Tn1k",
      "cell_type": "code",
      "source": [
        "import functools\n",
        "import gc\n",
        "import os\n",
        "from pprint import pprint\n",
        "import re\n",
        "import time\n",
        "\n",
        "from flax import nnx\n",
        "import grain\n",
        "import humanize\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import kagglehub\n",
        "import optax\n",
        "from orbax import checkpoint as ocp\n",
        "from qwix import lora\n",
        "import tensorflow_datasets as tfds\n",
        "from tqdm.auto import tqdm\n",
        "from tunix.models.gemma import data as data_lib\n",
        "from tunix.models.gemma import gemma as gemma_lib\n",
        "from tunix.models.gemma import params as params_lib\n",
        "from tunix.models.gemma import sampler as sampler_lib\n",
        "from tunix.rl.grpo.grpo_trainer import GrpoTrainer, GrpoTrainingConfig\n",
        "from tunix.sft import metrics_logger"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "Eu_NI9nHTn1k",
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters\n",
        "\n",
        "Let's define the configuration we are going to use. Note that this is by no\n",
        "means a \"perfect\" set of hyperparameters. To get good results, you will have\n",
        "to train the model for longer."
      ]
    },
    {
      "metadata": {},
      "id": "ZPPKme47Tn1k",
      "cell_type": "code",
      "source": [
        "# Data\n",
        "TRAIN_DATA_DIR = \"./data/train\"\n",
        "TEST_DATA_DIR = \"./data/test\"\n",
        "TRAIN_FRACTION = 1.0\n",
        "BATCH_SIZE = 2\n",
        "# Increase `NUM_BATCHES` and `MAX_STEPS` for better results.\n",
        "NUM_BATCHES = 10\n",
        "NUM_TEST_BATCHES = 2\n",
        "\n",
        "# Model\n",
        "MESH = [(1, 8), (\"fsdp\", \"tp\")]\n",
        "# LoRA\n",
        "RANK = 16\n",
        "ALPHA = 2.0\n",
        "\n",
        "# Train\n",
        "LEARNING_RATE = 1e-5\n",
        "B1 = 0.9\n",
        "B2 = 0.99\n",
        "WEIGHT_DECAY = 0.1\n",
        "\n",
        "\n",
        "# GRPO\n",
        "MAX_PROMPT_LENGTH = 256\n",
        "TOTAL_GENERATION_STEPS = 768\n",
        "NUM_GENERATIONS = 2\n",
        "NUM_ITERATIONS = 4\n",
        "BETA = 0.04\n",
        "EPSILON = 0.2\n",
        "TEMPERATURE = 0.9\n",
        "TOP_P = 1.0\n",
        "TOP_K = 50\n",
        "EVAL_EVERY_N_STEPS = 2\n",
        "NUM_EPOCHS = 1\n",
        "MAX_STEPS = int(NUM_BATCHES * BATCH_SIZE * NUM_EPOCHS * TRAIN_FRACTION)\n",
        "\n",
        "# Checkpoint saving\n",
        "INTERMEDIATE_CKPT_DIR = \"/content/intermediate_ckpt/\"\n",
        "CKPT_DIR = \"/content/ckpts/\"\n",
        "SAVE_INTERVAL_STEPS = 10\n",
        "MAX_TO_KEEP = 1"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "ngjtE-63Tn1k",
      "cell_type": "markdown",
      "source": [
        "## Utility functions"
      ]
    },
    {
      "metadata": {},
      "id": "wjMFOr7aTn1k",
      "cell_type": "code",
      "source": [
        "def show_hbm_usage():\n",
        "  \"\"\"Displays memory usage per device.\"\"\"\n",
        "  fmt_size = functools.partial(humanize.naturalsize, binary=True)\n",
        "\n",
        "  for d in jax.local_devices():\n",
        "    stats = d.memory_stats()\n",
        "    used = stats[\"bytes_in_use\"]\n",
        "    limit = stats[\"bytes_limit\"]\n",
        "    print(f\"Using {fmt_size(used)} / {fmt_size(limit)} ({used/limit:%}) on {d}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "6BtpYMlaTn1k",
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing\n",
        "\n",
        "First, let's define some special tokens. We instruct the model to first reason\n",
        "between the `\u003creasoning\u003e` and `\u003cend_reasoning\u003e` tokens. After\n",
        "reasoning, we expect it to provide the answer between the `\u003canswer\u003e` and\n",
        "`\u003cend_answer\u003e` tokens."
      ]
    },
    {
      "metadata": {},
      "id": "h6RGv1kSTn1k",
      "cell_type": "code",
      "source": [
        "reasoning_start = \"\u003cstart_reasoning\u003e\"\n",
        "reasoning_end = \"\u003cend_reasoning\u003e\"\n",
        "solution_start = \"\u003cstart_answer\u003e\"\n",
        "solution_end = \"\u003cend_answer\u003e\"\n",
        "\n",
        "SYSTEM_PROMPT = f\"\"\"You are given a problem.\n",
        "Think about the problem and provide your reasoning.\n",
        "Place it between {reasoning_start} and {reasoning_end}.\n",
        "Then, provide the final answer (i.e., just one numerical value)\n",
        "between {solution_start}{solution_end}.\"\"\"\n",
        "\n",
        "TEMPLATE = \"\"\"\u003cstart_of_turn\u003euser\n",
        "{system_prompt}\n",
        "\n",
        "{question}\u003cend_of_turn\u003e\n",
        "\u003cstart_of_turn\u003emodel\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "WASP9N5JTn1k",
      "cell_type": "markdown",
      "source": [
        "We use OpenAI's GSM8K dataset. GSM8K comprises grade school math word problems."
      ]
    },
    {
      "metadata": {},
      "id": "gTGjcSMNTn1k",
      "cell_type": "code",
      "source": [
        "def extract_hash_answer(text: str) -\u003e str | None:\n",
        "  if \"####\" not in text:\n",
        "    return None\n",
        "  return text.split(\"####\")[1].strip()\n",
        "\n",
        "\n",
        "def get_dataset(data_dir, split=\"train\") -\u003e grain.MapDataset:\n",
        "  # Download data\n",
        "  if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "\n",
        "  data = tfds.data_source(\n",
        "      \"gsm8k\",\n",
        "      split=split,\n",
        "      data_dir=data_dir,\n",
        "      builder_kwargs={\"file_format\": tfds.core.FileFormat.ARRAY_RECORD},\n",
        "      download=True,\n",
        "  )\n",
        "\n",
        "  dataset = (\n",
        "      grain.MapDataset.source(data)\n",
        "      .shuffle(seed=42)\n",
        "      .map(\n",
        "          lambda x: {\n",
        "              # passed to model forward pass\n",
        "              \"prompts\": TEMPLATE.format(\n",
        "                  system_prompt=SYSTEM_PROMPT,\n",
        "                  question=x[\"question\"].decode(\"utf-8\"),\n",
        "              ),\n",
        "              # passed to reward functions\n",
        "              \"question\": x[\"question\"].decode(\"utf-8\"),\n",
        "              # passed to reward functions\n",
        "              \"answer\": extract_hash_answer(x[\"answer\"].decode(\"utf-8\")),\n",
        "          }\n",
        "      )\n",
        "  )\n",
        "  return dataset"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "KXhOL6GyTn1k",
      "cell_type": "code",
      "source": [
        "dataset = get_dataset(TRAIN_DATA_DIR, \"train\").batch(BATCH_SIZE)[:NUM_BATCHES]\n",
        "\n",
        "if TRAIN_FRACTION == 1.0:\n",
        "  train_dataset = dataset.repeat(NUM_EPOCHS)\n",
        "  val_dataset = None\n",
        "else:\n",
        "  train_dataset = dataset[: int(len(dataset) * TRAIN_FRACTION)]\n",
        "  train_dataset = train_dataset.repeat(NUM_EPOCHS)\n",
        "\n",
        "  val_dataset = dataset[int(len(dataset) * TRAIN_FRACTION) :].repeat(NUM_EPOCHS)\n",
        "\n",
        "test_dataset = get_dataset(TEST_DATA_DIR, \"test\").batch(BATCH_SIZE)[\n",
        "    :NUM_TEST_BATCHES\n",
        "]\n",
        "\n",
        "len(train_dataset), len(val_dataset) if val_dataset is not None else 0, len(\n",
        "    test_dataset\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "k7n8L0VzTn1k",
      "cell_type": "markdown",
      "source": [
        "Let's see how one batch of the dataset looks like!\n"
      ]
    },
    {
      "metadata": {},
      "id": "5TF-wNQ2Tn1k",
      "cell_type": "code",
      "source": [
        "for ele in train_dataset[:1]:\n",
        "  pprint(ele)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "BZxBR7Y_Tn1k",
      "cell_type": "markdown",
      "source": [
        "## Load the policy model and the reference model\n",
        "\n",
        "The policy model is the model which is actually trained and whose weights are\n",
        "updated. The reference model is the model with which we compute KL\n",
        "divergence. This is to ensure that the policy updates are not huge and that it\n",
        "does not deviate too much from the reference model.\n",
        "\n",
        "Typically, the reference model is the base model, and the policy model is the\n",
        "same base model, but with LoRA parameters. Only the LoRA parameters are\n",
        "updated.\n",
        "\n",
        "To load the model, you need to be on [Kaggle](https://www.kaggle.com/) and need\n",
        "to have agreed to the Gemma license\n",
        "[here](https://www.kaggle.com/models/google/gemma/flax/)."
      ]
    },
    {
      "metadata": {},
      "id": "thp6hhqfTn1k",
      "cell_type": "code",
      "source": [
        "# Log in\n",
        "if \"KAGGLE_USERNAME\" not in os.environ or \"KAGGLE_KEY\" not in os.environ:\n",
        "  kagglehub.login()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "srH2s_jzTn1k",
      "cell_type": "code",
      "source": [
        "kaggle_ckpt_path = kagglehub.model_download(\"google/gemma/flax/2b-it\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "cIFAxgVOTn1k",
      "cell_type": "code",
      "source": [
        "# This is a workaround. The checkpoints on Kaggle don't work with NNX. So, we\n",
        "# load the model, save the checkpoint locally, and then reload the model\n",
        "# (sharded).\n",
        "params = params_lib.load_and_format_params(\n",
        "    os.path.join(kaggle_ckpt_path, \"2b-it\")\n",
        ")\n",
        "gemma = gemma_lib.Transformer.from_params(params, version=\"2b-it\")\n",
        "checkpointer = ocp.StandardCheckpointer()\n",
        "_, state = nnx.split(gemma)\n",
        "checkpointer.save(os.path.join(INTERMEDIATE_CKPT_DIR, \"state\"), state)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "JSz-XmQpTn1k",
      "cell_type": "code",
      "source": [
        "# Wait for the ckpt to save successfully.\n",
        "time.sleep(60)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "_w8kav8sTn1k",
      "cell_type": "code",
      "source": [
        "# Delete the intermediate model to save memory.\n",
        "del params\n",
        "del gemma\n",
        "del state\n",
        "gc.collect()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "m2KD-nmbTn1k",
      "cell_type": "code",
      "source": [
        "def get_ref_model(ckpt_path):\n",
        "  mesh = jax.make_mesh(*MESH)\n",
        "  abs_gemma: nnx.Module = nnx.eval_shape(\n",
        "      lambda: gemma_lib.Transformer(\n",
        "          gemma_lib.TransformerConfig.gemma_2b(), rngs=nnx.Rngs(params=0)\n",
        "      )\n",
        "  )\n",
        "  abs_state = nnx.state(abs_gemma)\n",
        "  abs_state = jax.tree.map(\n",
        "      lambda a, s: jax.ShapeDtypeStruct(a.shape, jnp.float32, sharding=s),\n",
        "      abs_state,\n",
        "      nnx.get_named_sharding(abs_state, mesh),\n",
        "  )\n",
        "  checkpointer = ocp.StandardCheckpointer()\n",
        "  restored_params = checkpointer.restore(ckpt_path, target=abs_state)\n",
        "\n",
        "  graph_def, _ = nnx.split(abs_gemma)\n",
        "  gemma = nnx.merge(graph_def, restored_params)\n",
        "  return gemma, mesh\n",
        "\n",
        "\n",
        "def get_lora_model(base_model, mesh):\n",
        "  lora_provider = lora.LoraProvider(\n",
        "      module_path=(\n",
        "          \".*q_einsum|.*kv_einsum|.*gate_proj|.*down_proj|.*up_proj|\"\n",
        "          \".*attn_vec_einsum\"\n",
        "      ),\n",
        "      rank=RANK,\n",
        "      alpha=ALPHA,\n",
        "  )\n",
        "\n",
        "  model_input = base_model.get_model_input()\n",
        "  lora_model = lora.apply_lora_to_model(\n",
        "      base_model, lora_provider, **model_input\n",
        "  )\n",
        "\n",
        "  with mesh:\n",
        "    state = nnx.state(lora_model)\n",
        "    pspecs = nnx.get_partition_spec(state)\n",
        "    sharded_state = jax.lax.with_sharding_constraint(state, pspecs)\n",
        "    nnx.update(lora_model, sharded_state)\n",
        "\n",
        "  return lora_model"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "kSdZ7aGhTn1k",
      "cell_type": "code",
      "source": [
        "# Reference model\n",
        "gemma, mesh = get_ref_model(\n",
        "    ckpt_path=os.path.join(INTERMEDIATE_CKPT_DIR, \"state\")\n",
        ")\n",
        "nnx.display(gemma)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "4i3CfJ1gTn1k",
      "cell_type": "code",
      "source": [
        "# Policy model\n",
        "lora_gemma = get_lora_model(gemma, mesh=mesh)\n",
        "nnx.display(lora_gemma)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "zLzR1tJfTn1k",
      "cell_type": "markdown",
      "source": [
        "## Define reward functions\n",
        "\n",
        "We define four reward functions:\n",
        "\n",
        "- reward if the format of the output exactly matches the instruction given in\n",
        "`TEMPLATE`;\n",
        "- reward if the format of the output approximately matches the instruction given\n",
        "in `TEMPLATE`;\n",
        "- reward if the answer is correct/partially correct;\n",
        "- Sometimes, the text between `\u003cstart_answer\u003e`, `\u003cend_answer\u003e` might not be one\n",
        "  number. So, extract the number, and reward the model if the answer is correct.\n",
        "\n",
        "First off, let's define a RegEx for checking whether the format matches"
      ]
    },
    {
      "metadata": {},
      "id": "C7Beft8wTn1k",
      "cell_type": "code",
      "source": [
        "match_format = re.compile(\n",
        "    rf\"^[\\s]{{0,}}\"\n",
        "    rf\"{reasoning_start}.+?{reasoning_end}.*?\"\n",
        "    rf\"{solution_start}(.+?){solution_end}\"\n",
        "    rf\"[\\s]{{0,}}$\",\n",
        "    flags=re.MULTILINE | re.DOTALL,\n",
        ")\n",
        "\n",
        "match_format.search(\n",
        "    f\"{reasoning_start}Let me think!{reasoning_end}\"\n",
        "    \"{solution_start}2{solution_end}\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "Fe1rF15zTn1k",
      "cell_type": "markdown",
      "source": [
        "Give the model a reward of 3 points if the format matches exactly."
      ]
    },
    {
      "metadata": {},
      "id": "_fhQ6pY2Tn1k",
      "cell_type": "code",
      "source": [
        "def match_format_exactly(prompts, completions, **kargs):\n",
        "  scores = []\n",
        "  for completion in completions:\n",
        "    score = 0\n",
        "    response = completion\n",
        "    # Match if format is seen exactly!\n",
        "    if match_format.search(response) is not None:\n",
        "      score += 3.0\n",
        "    scores.append(score)\n",
        "  return scores"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "sWdAdUHuTn1k",
      "cell_type": "markdown",
      "source": [
        "We also reward the model if the format of the output matches partially."
      ]
    },
    {
      "metadata": {},
      "id": "uOhO4f3-Tn1k",
      "cell_type": "code",
      "source": [
        "def match_format_approximately(prompts, completions, **kargs):\n",
        "  scores = []\n",
        "\n",
        "  for completion in completions:\n",
        "    score = 0\n",
        "    response = completion\n",
        "    # Count how many keywords are seen - we penalize if too many!\n",
        "    # If we see 1, then plus some points!\n",
        "    score += 0.5 if response.count(reasoning_start) == 1 else -0.5\n",
        "    score += 0.5 if response.count(reasoning_end) == 1 else -0.5\n",
        "    score += 0.5 if response.count(solution_start) == 1 else -0.5\n",
        "    score += 0.5 if response.count(solution_end) == 1 else -0.5\n",
        "    scores.append(score)\n",
        "  return scores"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "A2fNZDgTTn1k",
      "cell_type": "markdown",
      "source": [
        "Reward the model if the answer is correct. A reward is also given if the answer\n",
        "does not match exactly, i.e., based on how close the answer is to the correct\n",
        "value."
      ]
    },
    {
      "metadata": {},
      "id": "S8zcWsmhTn1k",
      "cell_type": "code",
      "source": [
        "def check_answer(prompts, completions, answer, **kargs):\n",
        "  responses = completions\n",
        "\n",
        "  extracted_responses = [\n",
        "      guess.group(1) if (guess := match_format.search(r)) is not None else None\n",
        "      for r in responses\n",
        "  ]\n",
        "\n",
        "  scores = []\n",
        "  for guess, true_answer in zip(extracted_responses, answer):\n",
        "    score = 0\n",
        "    if guess is None:\n",
        "      scores.append(0)\n",
        "      continue\n",
        "    # Correct answer gets 3 points!\n",
        "    if guess == true_answer:\n",
        "      score += 3.0\n",
        "    # Match if spaces are seen\n",
        "    elif guess.strip() == true_answer.strip():\n",
        "      score += 1.5\n",
        "    else:\n",
        "      # We also reward it if the answer is close via ratios!\n",
        "      # Ie if the answer is within some range, reward it!\n",
        "      try:\n",
        "        ratio = float(guess) / float(true_answer)\n",
        "        if ratio \u003e= 0.9 and ratio \u003c= 1.1:\n",
        "          score += 0.5\n",
        "        elif ratio \u003e= 0.8 and ratio \u003c= 1.2:\n",
        "          score += 0.25\n",
        "        else:\n",
        "          score -= 1.0  # Penalize wrong answers\n",
        "      except:\n",
        "        score -= 0.5  # Penalize\n",
        "    scores.append(score)\n",
        "  return scores"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "nIpOVv78Tn1k",
      "cell_type": "markdown",
      "source": [
        "Sometimes, the text between `\u003cstart_answer\u003e` and `\u003cend_answer\u003e` might not be one\n",
        "number; it can be a sentence. So, we extract the number and compare the answer."
      ]
    },
    {
      "metadata": {},
      "id": "NXvRtbk8Tn1k",
      "cell_type": "code",
      "source": [
        "match_numbers = re.compile(\n",
        "    rf\"{solution_start}.*?([\\d\\.]{{1,}})\", flags=re.MULTILINE | re.DOTALL\n",
        ")\n",
        "match_numbers.findall(f\"{solution_start}  0.34  {solution_end}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "oxZQAFKOTn1k",
      "cell_type": "code",
      "source": [
        "def check_numbers(prompts, completions, answer, **kargs):\n",
        "  question = kargs[\"question\"]\n",
        "  # question = prompts[0][-1][\"content\"]\n",
        "  responses = completions\n",
        "\n",
        "  extracted_responses = [\n",
        "      guess.group(1) if (guess := match_numbers.search(r)) is not None else None\n",
        "      for r in responses\n",
        "  ]\n",
        "\n",
        "  scores = []\n",
        "  print(\"START ============================\")\n",
        "  print(f\"Question: {question[0]}\")\n",
        "  print(f\"Answer: {answer[0]}\")\n",
        "  print(f\"Response: {responses[0]}\")\n",
        "  print(f\"Extracted: {extracted_responses[0]}\")\n",
        "  print(\"END ==============================\")\n",
        "  for guess, true_answer in zip(extracted_responses, answer):\n",
        "    if guess is None:\n",
        "      scores.append(0)\n",
        "      continue\n",
        "    # Convert to numbers\n",
        "    try:\n",
        "      true_answer = float(true_answer.strip())\n",
        "      guess = float(guess.strip())\n",
        "      scores.append(1.5 if guess == true_answer else 0.0)\n",
        "    except:\n",
        "      scores.append(0)\n",
        "      continue\n",
        "  return scores"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "AaiYMJxFTn1k",
      "cell_type": "markdown",
      "source": [
        "## Evaluate\n",
        "\n",
        "Before we train the model, let's evaluate the model on the test set so we can see the improvement post training.\n",
        "\n",
        "We evaluate it in two ways:\n",
        "\n",
        "1. Quantitative: We compute the accuracy and the percentage of samples which match the format we expect.\n",
        "2. Qualitative: Let's see the model outputs for a given question so that we can compare the generated output later."
      ]
    },
    {
      "metadata": {},
      "id": "_k58bOicUHJy",
      "cell_type": "code",
      "source": [
        "def generate(question, sampler, temperature=1.0, top_k=64, top_p=0.95):\n",
        "  \"\"\"Given prompt, generates text.\"\"\"\n",
        "\n",
        "  if isinstance(question, str):\n",
        "    input_batch = [\n",
        "        TEMPLATE.format(\n",
        "            system_prompt=SYSTEM_PROMPT,\n",
        "            question=question,\n",
        "        ),\n",
        "    ]\n",
        "  else:\n",
        "    input_batch = [\n",
        "        TEMPLATE.format(\n",
        "            system_prompt=SYSTEM_PROMPT,\n",
        "            question=q,\n",
        "        )\n",
        "        for q in question\n",
        "    ]\n",
        "\n",
        "  out_data = sampler(\n",
        "      input_strings=input_batch,\n",
        "      total_generation_steps=768,\n",
        "      temperature=temperature,\n",
        "      top_k=top_k,\n",
        "      top_p=top_p,\n",
        "      echo=False,\n",
        "  )\n",
        "\n",
        "  output = out_data.text\n",
        "  if isinstance(question, str):\n",
        "    return output[0]\n",
        "  return output\n",
        "\n",
        "\n",
        "def evaluate(dataset, sampler):\n",
        "  \"\"\"Computes accuracy and percentage of outputs matching the format.\"\"\"\n",
        "\n",
        "  corr = 0\n",
        "  corr_format = 0\n",
        "  total = 0\n",
        "\n",
        "  for batch in tqdm(dataset):\n",
        "    answers = batch[\"answer\"]\n",
        "    questions = batch[\"question\"]\n",
        "    responses = generate(questions, sampler)\n",
        "\n",
        "    for response, answer in zip(responses, answers):\n",
        "      # check answer\n",
        "      extracted_response = (\n",
        "          guess.group(1)\n",
        "          if (guess := match_numbers.search(response)) is not None\n",
        "          else \"-1000000\"\n",
        "      )\n",
        "      try:\n",
        "        if float(extracted_response.strip()) == float(answer.strip()):\n",
        "          corr += 1\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "      # check format\n",
        "      if match_format.search(response) is not None:\n",
        "        corr_format += 1\n",
        "\n",
        "      total += 1\n",
        "\n",
        "  return (corr / total * 100, corr_format / total * 100)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "HZMO-KflTn1k",
      "cell_type": "code",
      "source": [
        "gemma_tokenizer = data_lib.GemmaTokenizer(\n",
        "    os.path.join(kaggle_ckpt_path, \"tokenizer.model\")\n",
        ")\n",
        "sampler = sampler_lib.Sampler(\n",
        "    transformer=lora_gemma, vocab=gemma_tokenizer.vocab\n",
        ")\n",
        "\n",
        "question = (\n",
        "    \"Trevor and two of his neighborhood friends go to the toy shop every year \"\n",
        "    \"to buy toys. Trevor always spends $20 more than his friend Reed on toys, \"\n",
        "    \"and Reed spends 2 times as much money as their friend Quinn on the toys. \"\n",
        "    \"If Trevor spends $80 every year to buy his toys, calculate how much money \"\n",
        "    \"in total the three spend in 4 years.\"\n",
        ")\n",
        "print(generate(question, sampler))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "YQM-tzXWUmoE",
      "cell_type": "code",
      "source": [
        "accuracy, format_accuracy = evaluate(test_dataset, sampler)\n",
        "print(f\"{accuracy=}%, {format_accuracy=}%\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "-CmB2ZT9Tn1l",
      "cell_type": "markdown",
      "source": [
        "## Train\n",
        "\n",
        "Let's set up all the configs first - checkpointing, metric logging and training.\n",
        "We then train the model.\n",
        "\n",
        "Note: To get good results, it is advised to train the model for longer."
      ]
    },
    {
      "metadata": {},
      "id": "mHzdsYsGTn1l",
      "cell_type": "code",
      "source": [
        "# Ckpt saving\n",
        "checkpointing_options = ocp.CheckpointManagerOptions(\n",
        "    save_interval_steps=SAVE_INTERVAL_STEPS, max_to_keep=MAX_TO_KEEP\n",
        ")\n",
        "\n",
        "# Metrics logger\n",
        "metrics_logging_options = metrics_logger.MetricsLoggerOptions(\n",
        "    log_dir=\"/tmp/tensorboard/grpo\", flush_every_n_steps=20\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "_6VxFW1ZTn1l",
      "cell_type": "code",
      "source": [
        "# Training config\n",
        "training_config = GrpoTrainingConfig(\n",
        "    max_prompt_length=MAX_PROMPT_LENGTH,\n",
        "    total_generation_steps=TOTAL_GENERATION_STEPS,\n",
        "    num_generations=NUM_GENERATIONS,\n",
        "    num_iterations=NUM_ITERATIONS,\n",
        "    beta=BETA,\n",
        "    epsilon=EPSILON,\n",
        "    temperature=TEMPERATURE,\n",
        "    top_p=TOP_P,\n",
        "    top_k=TOP_K,\n",
        "    eval_every_n_steps=EVAL_EVERY_N_STEPS,\n",
        "    max_steps=MAX_STEPS,\n",
        "    # max_grad_norm=0.1,\n",
        "    # metrics logging\n",
        "    metrics_logging_options=metrics_logging_options,\n",
        "    # checkpoint saving\n",
        "    checkpoint_root_directory=CKPT_DIR,\n",
        "    checkpointing_options=checkpointing_options,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "OIe1lO08Tn1l",
      "cell_type": "code",
      "source": [
        "gemma_tokenizer = data_lib.GemmaTokenizer(\n",
        "    os.path.join(kaggle_ckpt_path, \"tokenizer.model\")\n",
        ")\n",
        "sampler = sampler_lib.Sampler(\n",
        "    transformer=lora_gemma,\n",
        "    vocab=gemma_tokenizer.vocab,\n",
        ")\n",
        "\n",
        "grpo_trainer = GrpoTrainer(\n",
        "    model=lora_gemma,\n",
        "    ref_model=gemma,  # use the base model as reference\n",
        "    reward_fns=[\n",
        "        match_format_exactly,\n",
        "        match_format_approximately,\n",
        "        check_answer,\n",
        "        check_numbers,\n",
        "    ],\n",
        "    sampler=sampler,\n",
        "    optimizer=optax.adamw(\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        b1=B1,\n",
        "        b2=B2,\n",
        "        weight_decay=WEIGHT_DECAY,\n",
        "    ),\n",
        "    training_config=training_config,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "S27XDebYTn1l",
      "cell_type": "code",
      "source": [
        "with mesh:\n",
        "  grpo_trainer.train(dataset)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "FzIP8glkTn1l",
      "cell_type": "markdown",
      "source": [
        "## Evaluate\n",
        "\n",
        "Let's evaluate our model!"
      ]
    },
    {
      "metadata": {},
      "id": "V-73HfP1Tn1l",
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import orbax.checkpoint as ocp\n",
        "\n",
        "trained_ckpt_path = os.path.join(CKPT_DIR, str(MAX_STEPS), \"model_params\")\n",
        "\n",
        "abs_params = jax.tree.map(\n",
        "    lambda x: jax.ShapeDtypeStruct(x.shape, x.dtype),\n",
        "    nnx.state(lora_gemma, nnx.LoRAParam),\n",
        ")\n",
        "checkpointer = ocp.StandardCheckpointer()\n",
        "trained_lora_params = checkpointer.restore(trained_ckpt_path, target=abs_params)\n",
        "\n",
        "nnx.update(\n",
        "    lora_gemma,\n",
        "    jax.tree.map(\n",
        "        lambda a, b: b,\n",
        "        nnx.state(lora_gemma, nnx.LoRAParam),\n",
        "        trained_lora_params,\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "1vY9kl-ITn1l",
      "cell_type": "code",
      "source": [
        "gemma_tokenizer = data_lib.GemmaTokenizer(\n",
        "    os.path.join(kaggle_ckpt_path, \"tokenizer.model\")\n",
        ")\n",
        "sampler = sampler_lib.Sampler(\n",
        "    transformer=lora_gemma, vocab=gemma_tokenizer.vocab\n",
        ")\n",
        "\n",
        "question = (\n",
        "    \"Trevor and two of his neighborhood friends go to the toy shop every year \"\n",
        "    \"to buy toys. Trevor always spends $20 more than his friend Reed on toys, \"\n",
        "    \"and Reed spends 2 times as much money as their friend Quinn on the toys. \"\n",
        "    \"If Trevor spends $80 every year to buy his toys, calculate how much money \"\n",
        "    \"in total the three spend in 4 years.\"\n",
        ")\n",
        "print(generate(question, sampler))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "nz0q_gGHqYz6",
      "cell_type": "code",
      "source": [
        "accuracy, format_accuracy = evaluate(test_dataset, sampler)\n",
        "print(f\"{accuracy=}%, {format_accuracy=}%\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "Jd9gpYVpUd3_",
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
